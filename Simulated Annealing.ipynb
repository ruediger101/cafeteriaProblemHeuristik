{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0bfb85-d543-4f5e-9203-55b94c89db78",
   "metadata": {},
   "source": [
    "# Quelle des Codes\n",
    "> https://machinelearningmastery.com/simulated-annealing-from-scratch-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23222408-07b3-4eca-a115-1f9cd65f4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">34 f([-0.78753544]) = 0.62021\n",
      ">35 f([-0.76914239]) = 0.59158\n",
      ">37 f([-0.68574854]) = 0.47025\n",
      ">39 f([-0.64797564]) = 0.41987\n",
      ">40 f([-0.58914623]) = 0.34709\n",
      ">41 f([-0.55446029]) = 0.30743\n",
      ">42 f([-0.41775702]) = 0.17452\n",
      ">43 f([-0.35038542]) = 0.12277\n",
      ">50 f([-0.15799045]) = 0.02496\n",
      ">66 f([-0.11089772]) = 0.01230\n",
      ">67 f([-0.09238208]) = 0.00853\n",
      ">72 f([-0.09145261]) = 0.00836\n",
      ">75 f([-0.05129162]) = 0.00263\n",
      ">93 f([-0.02854417]) = 0.00081\n",
      ">144 f([0.00864136]) = 0.00007\n",
      ">149 f([0.00753953]) = 0.00006\n",
      ">167 f([-0.00640394]) = 0.00004\n",
      ">225 f([-0.00044965]) = 0.00000\n",
      ">503 f([-0.00036261]) = 0.00000\n",
      ">512 f([0.00013605]) = 0.00000\n",
      "Done!\n",
      "f([0.00013605]) = 0.000000\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from numpy import exp\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "\n",
    "# objective function\n",
    "def objective(x):\n",
    "\treturn x[0]**2.0\n",
    "\n",
    "# simulated annealing algorithm\n",
    "def simulated_annealing(objective, bounds, n_iterations, step_size, temp):\n",
    "\t# generate an initial point\n",
    "\tbest = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\t# evaluate the initial point\n",
    "\tbest_eval = objective(best)\n",
    "\t# current working solution\n",
    "\tcurr, curr_eval = best, best_eval\n",
    "\t# run the algorithm\n",
    "\tfor i in range(n_iterations):\n",
    "\t\t# take a step\n",
    "\t\tcandidate = curr + randn(len(bounds)) * step_size\n",
    "\t\t# evaluate candidate point\n",
    "\t\tcandidate_eval = objective(candidate)\n",
    "\t\t# check for new best solution\n",
    "\t\tif candidate_eval < best_eval:\n",
    "\t\t\t# store new best point\n",
    "\t\t\tbest, best_eval = candidate, candidate_eval\n",
    "\t\t\t# report progress\n",
    "\t\t\tprint('>%d f(%s) = %.5f' % (i, best, best_eval))\n",
    "\t\t# difference between candidate and current point evaluation\n",
    "\t\tdiff = candidate_eval - curr_eval\n",
    "\t\t# calculate temperature for current epoch\n",
    "\t\tt = temp / float(i + 1)\n",
    "\t\t# calculate metropolis acceptance criterion\n",
    "\t\tmetropolis = exp(-diff / t)\n",
    "\t\t# check if we should keep the new point\n",
    "\t\tif diff < 0 or rand() < metropolis:\n",
    "\t\t\t# store the new current point\n",
    "\t\t\tcurr, curr_eval = candidate, candidate_eval\n",
    "\treturn [best, best_eval]\n",
    "\n",
    "# seed the pseudorandom number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-5.0, 5.0]])\n",
    "# define the total iterations\n",
    "n_iterations = 1000\n",
    "# define the maximum step size\n",
    "step_size = 0.1\n",
    "# initial temperature\n",
    "temp = 10\n",
    "# perform the simulated annealing search\n",
    "best, score = simulated_annealing(objective, bounds, n_iterations, step_size, temp)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fab715",
   "metadata": {},
   "source": [
    "# Quelle\n",
    "> https://pythonmana.com/2021/05/20210502184221296q.html\n",
    "\n",
    "**Achtung: Einrückung händisch korrigiert evtl. noch falsch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50de64c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_Initial:3.000000,1.000000,\tf(x_Initial):-39.000000\n",
      "i:0,t(i):100.00, badAccept:0.958333, f(x)_best:-152.000000\n",
      "i:10,t(i):81.71, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:20,t(i):66.76, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:30,t(i):54.55, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:40,t(i):44.57, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:50,t(i):36.42, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:60,t(i):29.76, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:70,t(i):24.31, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:80,t(i):19.86, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:90,t(i):16.23, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:100,t(i):13.26, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:110,t(i):10.84, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:120,t(i):8.85, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:130,t(i):7.23, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:140,t(i):5.91, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:150,t(i):4.83, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:160,t(i):3.95, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:170,t(i):3.22, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:180,t(i):2.63, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:190,t(i):2.15, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:200,t(i):1.76, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:210,t(i):1.44, badAccept:1.000000, f(x)_best:-98.000000\n",
      "i:220,t(i):1.17, badAccept:1.000000, f(x)_best:-98.000000\n",
      "improve:12\n",
      "\n",
      "Optimization by simulated annealing algorithm:\n",
      "\tx[0] = 8.0\n",
      "\tx[1] = 2.0\n",
      "\n",
      "\tf(x) = -98.0\n"
     ]
    }
   ],
   "source": [
    "# Simulated annealing algorithm Program ： Solving linear programming problems （ Integer programming ）\n",
    "\n",
    "# Program: SimulatedAnnealing_v4.py\n",
    "\n",
    "# Purpose: Simulated annealing algorithm for function optimization\n",
    "\n",
    "# v4.0: Integer programming ： The value of decision variable is integer （ Both the initial value and the new solution are randomly generated integers ）\n",
    "\n",
    "# Copyright 2021 YouCans, XUPT\n",
    "\n",
    "# Crated：2021-05-01\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import math # The import module \n",
    "\n",
    "import random # The import module \n",
    "\n",
    "import pandas as pd # The import module YouCans, XUPT\n",
    "\n",
    "import numpy as np # The import module numpy, And abbreviated as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "# Subroutines ： Define the objective function of the optimization problem \n",
    "\n",
    "def cal_Energy(X, nVar, mk): # m(k)： Punishment factor , With the number of iterations k Gradually increase \n",
    "\n",
    "    p1 = (max(0, 6*X[0]+5*X[1]-60))**2\n",
    "\n",
    "    p2 = (max(0, 10*X[0]+20*X[1]-150))**2\n",
    "\n",
    "    fx = -(10*X[0]+9*X[1])\n",
    "\n",
    "    return fx+mk*(p1+p2)\n",
    "# Subroutines ： Parameter setting of simulated annealing algorithm \n",
    "\n",
    "def ParameterSetting():\n",
    "\n",
    "    cName = \"funcOpt\" # Define problem name YouCans, XUPT\n",
    "\n",
    "    nVar = 2 # Given the number of arguments ,y=f(x1,..xn)\n",
    "\n",
    "    xMin = [0, 0] # Given the lower bound of the search space ,x1_min,..xn_min\n",
    "\n",
    "    xMax = [8, 8] # Given the upper limit of the search space ,x1_max,..xn_max\n",
    "    tInitial = 100.0 # Set the initial annealing temperature (initial temperature)\n",
    "\n",
    "    tFinal = 1 # Set the ending annealing temperature (stop temperature)\n",
    "\n",
    "    alfa = 0.98 # Set the cooling parameters ,T(k)=alfa*T(k-1)\n",
    "\n",
    "    meanMarkov = 100 # Markov Chain length , That is, the number of internal circulation runs \n",
    "\n",
    "    scale = 0.5 # Define the search step size , It can be set to a fixed value or gradually reduced \n",
    "\n",
    "    return cName, nVar, xMin, xMax, tInitial, tFinal, alfa, meanMarkov, scale\n",
    "# Simulated annealing algorithm \n",
    "\n",
    "def OptimizationSSA(nVar,xMin,xMax,tInitial,tFinal,alfa,meanMarkov,scale):\n",
    "\n",
    "    # ====== Initialize the random number generator ======\n",
    "    \n",
    "    randseed = random.randint(1, 100)\n",
    "    \n",
    "    random.seed(randseed) # Random number generator set seed , It can also be set to a specified integer\n",
    "    # ====== The initial solution of the optimization problem is generated randomly ======\n",
    "    \n",
    "    xInitial = np.zeros((nVar)) # initialization , Create array \n",
    "    \n",
    "    for v in range(nVar):\n",
    "    \n",
    "        # xInitial[v] = random.uniform(xMin[v], xMax[v]) # produce [xMin, xMax] Random real numbers of ranges \n",
    "    \n",
    "        xInitial[v] = random.randint(xMin[v], xMax[v]) # produce [xMin, xMax] The random integer of the range \n",
    "\n",
    "    # Call subfunction cal_Energy Calculate the objective function value of the current solution \n",
    "\n",
    "    fxInitial = cal_Energy(xInitial, nVar, 1) # m(k)： Punishment factor , The initial value is 1\n",
    "    # ====== Simulated annealing algorithm initialization ======\n",
    "\n",
    "    xNew = np.zeros((nVar)) # initialization , Create array \n",
    "\n",
    "    xNow = np.zeros((nVar)) # initialization , Create array \n",
    "\n",
    "    xBest = np.zeros((nVar)) # initialization , Create array \n",
    "\n",
    "    xNow[:] = xInitial[:] # Initialize the current solution , Set the initial solution to the current solution \n",
    "\n",
    "    xBest[:] = xInitial[:] # Initialize the optimal solution , Set the current solution as the optimal solution \n",
    "\n",
    "    fxNow = fxInitial # Set the objective function of the initial solution to the current value \n",
    "\n",
    "    fxBest = fxInitial # Set the objective function of the current solution to the optimal value \n",
    "\n",
    "    print('x_Initial:{:.6f},{:.6f},\\tf(x_Initial):{:.6f}'.format(xInitial[0], xInitial[1], fxInitial))\n",
    "    recordIter = [] # initialization , Number of external cycles \n",
    "\n",
    "    recordFxNow = [] # initialization , The objective function value of the current solution \n",
    "\n",
    "    recordFxBest = [] # initialization , The objective function value of the best solution \n",
    "\n",
    "    recordPBad = [] # initialization , The acceptance probability of the inferior solution \n",
    "\n",
    "    kIter = 0 # The number of iterations of the outer loop , The number of temperature states \n",
    "    \n",
    "    totalMar = 0 # A total of Markov Chain length \n",
    "    \n",
    "    totalImprove = 0 # fxBest The number of improvements \n",
    "    \n",
    "    nMarkov = meanMarkov # Fixed length Markov chain\n",
    "    # ====== Start simulated annealing optimization ======\n",
    "    \n",
    "    # Outer loop , Until the current temperature reaches the end temperature \n",
    "    \n",
    "    tNow = tInitial # Initialize the current temperature (current temperature)\n",
    "    \n",
    "    while tNow >= tFinal: # Outer loop , Until the current temperature reaches the end temperature \n",
    "    \n",
    "        # At the current temperature , Do it enough times (nMarkov) To achieve thermal equilibrium \n",
    "\n",
    "        kBetter = 0 # The number of times a good solution is obtained \n",
    "\n",
    "        kBadAccept = 0 # The number of times a bad solution is accepted \n",
    "\n",
    "        kBadRefuse = 0 # The number of times a bad solution is rejected\n",
    "        # --- Inner loop , The number of cycles is Markov Chain length \n",
    "\n",
    "        for k in range(nMarkov): # Inner loop , The number of cycles is Markov Chain length \n",
    "        \n",
    "            totalMar += 1 # total Markov Chain length counter\n",
    "            # --- New solutions \n",
    "\n",
    "            # New solutions ： A new solution is generated by random perturbation near the current solution , The new solution must be in [min,max] Within the scope of \n",
    "\n",
    "            # programme 1： Only right n One of the variables is perturbed , Other n-1 Two variables remain unchanged \n",
    "\n",
    "            xNew[:] = xNow[:]\n",
    "\n",
    "            v = random.randint(0, nVar-1) # produce [0,nVar-1] Random number between \n",
    "\n",
    "            xNew[v] = round(xNow[v] + scale * (xMax[v]-xMin[v]) * random.normalvariate(0, 1))\n",
    "\n",
    "            # Satisfy that the decision variable is an integer , Use the simplest solution ： The resulting new solution is rounded to the nearest whole \n",
    "\n",
    "            xNew[v] = max(min(xNew[v], xMax[v]), xMin[v]) # Make sure the new solution is [min,max] Within the scope of\n",
    "            # --- Calculate the objective function and the energy difference \n",
    "\n",
    "            # Call subfunction cal_Energy Calculate the objective function value of the new solution \n",
    "\n",
    "            fxNew = cal_Energy(xNew, nVar, kIter)\n",
    "\n",
    "            deltaE = fxNew - fxNow\n",
    "            # --- Press Metropolis The criteria accept new interpretations \n",
    "\n",
    "            # Accept judgment ： according to Metropolis The criteria decide whether to accept the new interpretation \n",
    "\n",
    "            if fxNew < fxNow: # Better solution ： If the objective function of the new solution is better than the current solution , Then accept the new explanation \n",
    "            \n",
    "                accept = True\n",
    "\n",
    "                kBetter += 1\n",
    "\n",
    "            else: # Tolerance solution ： If the objective function of the new solution is worse than the current solution , The new solution is accepted with a certain probability \n",
    "            \n",
    "                pAccept = math.exp(-deltaE / tNow) # Calculate the state transition probability of the tolerant solution \n",
    "\n",
    "                if pAccept > random.random():\n",
    "            \n",
    "                    accept = True # Accept the bad solution \n",
    "\n",
    "                    kBadAccept += 1\n",
    "\n",
    "                else:\n",
    "            \n",
    "                    accept = False # Refuse inferior solutions \n",
    "\n",
    "                    kBadRefuse += 1\n",
    "            # Save the new solution \n",
    "\n",
    "            if accept == True: # If you accept the new explanation , The new solution is saved as the current solution \n",
    "            \n",
    "                xNow[:] = xNew[:]\n",
    "\n",
    "                fxNow = fxNew\n",
    "\n",
    "            if fxNew < fxBest: # If the objective function of the new solution is better than the optimal solution , Then the new solution is saved as the optimal solution \n",
    "            \n",
    "                fxBest = fxNew\n",
    "\n",
    "                xBest[:] = xNew[:]\n",
    "\n",
    "                totalImprove += 1\n",
    "\n",
    "            scale = scale*0.99 # Variable search step size , Gradually reduce the search scope , Improve search accuracy\n",
    "        # --- Data processing after the end of the inner loop \n",
    "\n",
    "        # Complete the current temperature search , Save data and output \n",
    "\n",
    "        pBadAccept = kBadAccept / (kBadAccept + kBadRefuse) # The acceptance probability of the inferior solution \n",
    "\n",
    "        recordIter.append(kIter) # The current number of external loops \n",
    "\n",
    "        recordFxNow.append(round(fxNow, 4)) # The objective function value of the current solution \n",
    "\n",
    "        recordFxBest.append(round(fxBest, 4)) # The objective function value of the best solution \n",
    "\n",
    "        recordPBad.append(round(pBadAccept, 4)) # The objective function value of the best solution\n",
    "        if kIter%10 == 0: # Modular arithmetic , The remainder of the quotient \n",
    "        \n",
    "            print('i:{},t(i):{:.2f}, badAccept:{:.6f}, f(x)_best:{:.6f}'.\\\n",
    "                  format(kIter, tNow, pBadAccept, fxBest))\n",
    "        # Slow down to a new temperature , The cooling curve ：T(k)=alfa*T(k-1)\n",
    "\n",
    "        tNow = tNow * alfa\n",
    "\n",
    "        kIter = kIter + 1\n",
    "\n",
    "        fxBest = cal_Energy(xBest, nVar, kIter) # Because the penalty factor increases after iteration , Then we need to reconstruct the augmented objective function \n",
    "    \n",
    "    # ====== End the simulated annealing process ======\n",
    "    print('improve:{:d}'.format(totalImprove))\n",
    "    \n",
    "    return kIter,xBest,fxBest,fxNow,recordIter,recordFxNow,recordFxBest,recordPBad\n",
    "# Results check and output \n",
    "\n",
    "def ResultOutput(cName,nVar,xBest,fxBest,kIter,recordFxNow,recordFxBest,recordPBad,recordIter):\n",
    "\n",
    "    # ====== Check and output the optimization results ======\n",
    "\n",
    "    fxCheck = cal_Energy(xBest, nVar, kIter)\n",
    "\n",
    "    if abs(fxBest - fxCheck)>1e-3: # Test the objective function \n",
    "\n",
    "        print(\"Error 2: Wrong total millage!\")\n",
    "\n",
    "        return\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"\\nOptimization by simulated annealing algorithm:\")\n",
    "\n",
    "        for i in range(nVar):\n",
    "\n",
    "            print('\\tx[{}] = {:.1f}'.format(i,xBest[i]))\n",
    "\n",
    "        print('\\n\\tf(x) = {:.1f}'.format(cal_Energy(xBest,nVar,0)))\n",
    "    return\n",
    "# The main program \n",
    "\n",
    "def main():\n",
    "    # Parameter setting , Parameter definition of optimization problem , Parameter setting of simulated annealing algorithm \n",
    "    \n",
    "    [cName, nVar, xMin, xMax, tInitial, tFinal, alfa, meanMarkov, scale] = ParameterSetting()\n",
    "    \n",
    "    # print([nVar, xMin, xMax, tInitial, tFinal, alfa, meanMarkov, scale])\n",
    "    # Simulated annealing algorithm \n",
    "    [kIter,xBest,fxBest,fxNow,recordIter,recordFxNow,recordFxBest,recordPBad] \\\n",
    "    = OptimizationSSA(nVar,xMin,xMax,tInitial,tFinal,alfa,meanMarkov,scale)\n",
    "    \n",
    "    # print(kIter, fxNow, fxBest, pBadAccept)\n",
    "    # Results check and output \n",
    "    \n",
    "    ResultOutput(cName, nVar,xBest,fxBest,kIter,recordFxNow,recordFxBest,recordPBad,recordIter)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2111cc88deee10a0e4c6edf2b0a6b735e1d661925d7e2de2d6f6497830c2392"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
